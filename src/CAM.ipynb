{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from CAM import CAM\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 131)               67203     \n",
      "=================================================================\n",
      "Total params: 14,781,891\n",
      "Trainable params: 14,781,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  load_model('../models/vgg16-pretrained-rmsprop.model/')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"./4_100.jpg\"\n",
    "orig = cv2.imread(IMAGE_PATH)\n",
    "resized = cv2.resize(orig, (224, 224))\n",
    "# load the input image from disk (in Keras/TensorFlow format) and\n",
    "# preprocess it\n",
    "image = load_img(IMAGE_PATH, target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = imagenet_utils.preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 14\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(image)\n",
    "i = np.argmax(preds[0])\n",
    "print(\"CLASS\", i)\n",
    "# decode the ImageNet predictions to obtain the human-readable label\n",
    "# decoded = imagenet_utils.decode_predictions(preds)\n",
    "# print(decoded)\n",
    "# (imagenetID, label, prob) = decoded[0][0]\n",
    "# label = \"{}: {:.2f}%\".format(label, prob * 100)\n",
    "# print(\"[INFO] {}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  7  7 ...  3  3  3]\n",
      " [ 7  7  7 ...  3  3  3]\n",
      " [ 7  7  7 ...  3  3  3]\n",
      " ...\n",
      " [ 8  8  8 ... 13 13 13]\n",
      " [ 8  8  8 ... 13 13 13]\n",
      " [ 8  8  8 ... 13 13 13]] (224, 224) (1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "cam = CAM(model, i)\n",
    "heatmap = cam.compute_heatmap(image)\n",
    "print(heatmap, heatmap.shape, image.shape)\n",
    "# resize the resulting heatmap to the original input image dimensions\n",
    "# and then overlay heatmap on top of the image\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
    "(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw the predicted label on the output image\n",
    "# cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\n",
    "# cv2.putText(output, 'result', (10, 25), cv2.FONT_HERSHEY_SIMPLEX,0.8, (255, 255, 255), 2)\n",
    "# display the original image and resulting heatmap and output image\n",
    "# to our screen\n",
    "output = np.vstack([orig, heatmap, output])\n",
    "output = imutils.resize(output, height=700)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
